{
  "hash": "033047b75a77a436543da167fc84c05c",
  "result": {
    "markdown": "---\ntitle: \"Plot geom_sf() On OpenStreetMap Tiles\"\nauthor: Hiroaki Yutani\ndate: \"2018-06-09\"\ncategories: [\"ggplot2\", \"GIS\"]\nformat:\n  html:\n    toc: true\n    toc-title: \"Contents\"\n    toc-location: left\n---\n\n\n\n\n[mapview](https://r-spatial.github.io/mapview/) is a very nice package to explore an `sf` object. It can overlay `sf` object on the map images:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnc <- sf::read_sf(system.file(\"shape/nc.shp\", package=\"sf\"))\n\n# mapview::mapview(nc)\n```\n:::\n\n\nBut, how can I do this with ggplot2? (My friend told me `mapview::mapshot()` can generate a PNG, but I want to do this with ggplot2!)\n\n## RTFM\n\nBefore anything, I need to read [Tile Usage Policy](https://operations.osmfoundation.org/policies/tiles/) to use the OpenStreetMap tiles. For \"Requirements\" section, this is important:\n\n> Clearly display license attribution.\n\nAccording to [Copyright and License](https://www.openstreetmap.org/copyright), it's so simple as just adding this caption to my plots:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlabs(caption = \"\\U00a9 OpenStreetMap contributors\")\n```\n:::\n\n\nFor \"Technical Usage Requirements\" section, I have to read this more carefully. Let's look at the requirements one by one.\n\n> Valid HTTP User-Agent identifying application. Faking another app's User-Agent WILL get you blocked.\n\nOh, it seems I need to add `User-Agent` header. OK, let's invent some nice name... If I use `httr::GET()`, the code will probably like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGET(\n  \"https://...\",\n  add_headers(`User-Agent` = \"Yutani's blog post\")\n)\n```\n:::\n\n\n> If known, a valid HTTP Referer.\n\nI don't have `Referer`s, so I skip this.\n\n> DO NOT send no-cache headers. (\"Cache-Control: no-cache\", \"Pragma: no-cache\" etc.)\n\nI do nothing other than swearing I'll never use this header.\n\n> Cache Tile downloads locally according to HTTP Expiry Header, alternatively a minimum of 7 days.\n\nAh, this is important. Let's implement later.\n\n> Maximum of 2 download threads. (Unmodified web browsers' download thread limits are acceptable.)\n\nFortunately, I'm not good at parallelism, so this is fine.\n\n## Get Tile URLs\n\nAccording to [Slippy map tilenames](https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames#Tile_servers), the URL of a tile follows this format:\n\n    https://[abc].tile.openstreetmap.org/zoom/x/y.png \n\nI have to fill these four parts:\n\n-   `[abc]`\n-   `zoom`\n-   `x`\n-   `y`\n\nLet's look at these one by one.\n\n### `[abc]`\n\n`[abc]` means there are three domains; `a.tile.openstreetmap.org`, `b.tile.openstreetmap.org`, `c.tile.openstreetmap.org`. But, why? It says:\n\n> Browser-based applications can thus request multiple tiles from multiple subdomains faster than from one subdomain.\n\nSo, as I'm not browser-based, I can choose arbitrary one.\n\n### `zoom`\n\nZoom parameter is an integer number from 0 to 19. If `zoom` is 0, there's only one tile. Likewise 2 x 2 tiles for zoom `1`, 4 x 4 tiles for zoom `2`, and so on. Then, which one should I choose? This can be roughly determined based on the size of the bbox (boundary box) of the `sf` object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get the bbox\nb <- sf::st_bbox(nc)\nb\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     xmin      ymin      xmax      ymax \n-84.32385  33.88199 -75.45698  36.58965 \n```\n:::\n\n```{.r .cell-code}\n# calculate the lengths of x and y of the bbox\nx_len <- b[\"xmax\"] - b[\"xmin\"]\ny_len <- b[\"ymax\"] - b[\"ymin\"]\n\n# calculate the minimum zoom level that is smaller than the lengths\nx_zoom <- sum(x_len < 360 / 2^(0:19)) - 1\ny_zoom <- sum(y_len < 170.1022 / 2^(0:19)) - 1\n\nzoom <- min(x_zoom, y_zoom)\nzoom\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\nBut, since the tile is so small as 256 × 256 pixel, it's often better to zoom more.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nzoom <- zoom + 2\n```\n:::\n\n\n(I'm not sure how to do this correctly, I guess the zoom level should be determined by the size of the plot canvas, not the bbox.)\n\n### `x` and `y`\n\nA pair of `x` and `y` represents the location of a tile. `x` corresponds to longitude, `y` to latitude. If the `zoom` is given, I can convert longitudes and latitudes to `x` and `y` according to the [pseudo code on OpenStreetMap's wiki](https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames#Pseudo-code):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsec <- function(x) {\n  1 / cos(x)\n}\n\nlonlat2xy <- function(lat_deg, lon_deg, zoom) {\n  n <- 2^zoom\n\n  x <- (n * (lat_deg + 180)) %/% 360\n  lon_rad <- lon_deg * pi / 180\n  y <- (n * (1 - log(tan(lon_rad) + sec(lon_rad)) / pi)) %/% 2\n\n  list(x = x, y = y)\n}\n```\n:::\n\n\nBut, how can I find the set of tiles which covers the whole bbox?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\np <- ggplot(nc) +\n  geom_sf() +\n  annotate(\"rect\", xmin = b[\"xmin\"], xmax = b[\"xmax\"], ymin = b[\"ymin\"], ymax = b[\"ymax\"],\n           colour = alpha(\"red\", 0.4), fill = \"transparent\", linetype = \"dashed\", size = 1.2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nsize aesthetic has been deprecated for use with lines as of ggplot2 3.4.0\nℹ Please use linewidth aesthetic instead\nThis message is displayed once every 8 hours.\n```\n:::\n\n```{.r .cell-code}\np\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/bbox-plot-1.png){width=672}\n:::\n:::\n\n\nThis problem can be simplified; I can focus only two corners, the north-west and the south-east. If I calculate which tiles of `x` and `y` those two points fall in, I can find the rest of the tiles by filling the sequences of `x` and `y` between these two tiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorners <- expand.grid(x = b[c(1, 3)], y = b[c(2, 4)])\n\np +\n  geom_point(aes(x, y), corners[2:3,], colour = \"red\", size = 5)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-corner-1.png){width=672}\n:::\n:::\n\n\nHere's the tiles:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxy <- lonlat2xy(b[c(\"xmin\", \"xmax\")], b[c(\"ymin\", \"ymax\")], zoom)\n\ntiles <- expand.grid(x = seq(xy$x[\"xmin\"], xy$x[\"xmax\"]),\n                     y = seq(xy$y[\"ymin\"], xy$y[\"ymax\"]))\n\ntiles\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   x  y\n1 34 51\n2 35 51\n3 36 51\n4 37 51\n5 34 50\n6 35 50\n7 36 50\n8 37 50\n```\n:::\n:::\n\n\n### Tile URLs\n\nFrom the results above, I can yield the URLs of the tiles:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurls <- sprintf(\"https://a.tile.openstreetmap.org/%d/%d/%d.png\", zoom, tiles$x, tiles$y)\nurls\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"https://a.tile.openstreetmap.org/7/34/51.png\"\n[2] \"https://a.tile.openstreetmap.org/7/35/51.png\"\n[3] \"https://a.tile.openstreetmap.org/7/36/51.png\"\n[4] \"https://a.tile.openstreetmap.org/7/37/51.png\"\n[5] \"https://a.tile.openstreetmap.org/7/34/50.png\"\n[6] \"https://a.tile.openstreetmap.org/7/35/50.png\"\n[7] \"https://a.tile.openstreetmap.org/7/36/50.png\"\n[8] \"https://a.tile.openstreetmap.org/7/37/50.png\"\n```\n:::\n:::\n\n\nOK, now I can download them. But, before that, let's confirm that the tiles really cover the expected area.\n\n### Tile positions\n\nTo plot these tiles, I calculate the north-west corner of a tile by the following code (the pseudo code for this is also found on the wiki):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxy2lonlat <- function(x, y, zoom) {\n  n <- 2^zoom\n\n  lon_deg <- x / n * 360.0 - 180.0\n  lat_rad <- atan(sinh(pi * (1 - 2 * y / n)))\n  lat_deg <- lat_rad * 180.0 / pi\n\n  list(lon_deg = lon_deg, lat_deg = lat_deg)\n}\n```\n:::\n\n\nThen, south-east corners can be also calculated easily. Let's calculate the both corners and bind them to a data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(dplyr, warn.conflicts = FALSE)\n\nnw_corners <- pmap_dfr(tiles, xy2lonlat, zoom = zoom)\n# add 1 to x and y to get the south-east corners\nse_corners <- pmap_dfr(mutate_all(tiles, `+`, 1), xy2lonlat, zoom = zoom)\n\nnames(nw_corners) <- c(\"xmin\", \"ymax\")\nnames(se_corners) <- c(\"xmax\", \"ymin\")\n\ntile_positions <- bind_cols(nw_corners, se_corners)\ntile_positions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 4\n   xmin  ymax  xmax  ymin\n  <dbl> <dbl> <dbl> <dbl>\n1 -84.4  34.3 -81.6  32.0\n2 -81.6  34.3 -78.8  32.0\n3 -78.8  34.3 -75.9  32.0\n4 -75.9  34.3 -73.1  32.0\n5 -84.4  36.6 -81.6  34.3\n6 -81.6  36.6 -78.8  34.3\n7 -78.8  36.6 -75.9  34.3\n8 -75.9  36.6 -73.1  34.3\n```\n:::\n:::\n\n\nNow I can plot the empty tiles as below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np +\n  geom_point(aes(x, y), corners[2:3,], colour = \"red\", size = 5) +\n  geom_rect(data = tile_positions,\n            aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),\n            colour = \"blue\", fill = \"transparent\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-empty-tiles-1.png){width=672}\n:::\n:::\n\n\nYay, confirmed! Let's proceed to the next step.\n\n## Get tile data\n\nIf I just get the response from a URL, `httr::GET()` is handy. But, this time, for the requirement of caching, I have to save the responses to disk first. So, I use `curl::curl_download()` here.\n\nNote that PNG data can be read into R session by `png::readPNG()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_tile <- function(url) {\n  # build a local path\n  path <- stringr::str_extract(url, \"/\\\\d+/\\\\d+/\\\\d+.png\")\n  local_png <- here::here(file.path(\"data\", \"osm-tiles\", path))\n\n  if (!file.exists(local_png)) {\n    dir.create(dirname(local_png), showWarnings = FALSE, recursive = TRUE)\n    \n    # add header\n    h <- curl::new_handle()\n    curl::handle_setheaders(h, `User-Agent` = \"Yutani's blog post\")\n    \n    curl::curl_download(url, destfile = local_png)\n  }\n\n  png::readPNG(local_png)\n}\n```\n:::\n\n\nThen, let's get all tiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npngs <- map(urls, get_tile)\n```\n:::\n\n\n## Plot tiles\n\nTo plot tiles, I use `annotation_raster()`, whose necessary arguments are:\n\n-   `raster`\n-   `xmin`\n-   `xmax`\n-   `ymin`\n-   `ymax`\n\nThe first one is `pngs` and the others are contained in `tile_positions`. So, let's combine them so that I can use `pmap()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nargs <- tile_positions %>%\n  mutate(raster = pngs)\n\nargs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 5\n   xmin  ymax  xmax  ymin raster               \n  <dbl> <dbl> <dbl> <dbl> <list>               \n1 -84.4  34.3 -81.6  32.0 <dbl [256 × 256 × 3]>\n2 -81.6  34.3 -78.8  32.0 <dbl [256 × 256 × 3]>\n3 -78.8  34.3 -75.9  32.0 <dbl [256 × 256 × 3]>\n4 -75.9  34.3 -73.1  32.0 <dbl [256 × 256 × 3]>\n5 -84.4  36.6 -81.6  34.3 <dbl [256 × 256 × 3]>\n6 -81.6  36.6 -78.8  34.3 <dbl [256 × 256 × 3]>\n7 -78.8  36.6 -75.9  34.3 <dbl [256 × 256 × 3]>\n8 -75.9  36.6 -73.1  34.3 <dbl [256 × 256 × 3]>\n```\n:::\n:::\n\n\nNow I can plot tiles at last.\n\n\n::: {.cell preview='true'}\n\n```{.r .cell-code}\nggplot(nc) +\n  pmap(args, annotation_raster, interpolate = TRUE) +\n  geom_sf(fill = alpha(\"red\", 0.3)) +\n  # don't forget the license notice!\n  labs(caption = \"\\U00a9 OpenStreetMap contributors\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-1.png){width=672}\n:::\n:::\n\n\nDone!\n\nBut, I didn't expect the code would be this long... Maybe I need to create a package for this.\n\n## Caveats\n\n<strike>Note that, I didn't care about the CRS because `nc`'s CRS is fortunately EPSG 3857, which OpenStreetMap uses. If the `sf` object I want to plot has the different CRS, there may be a bit more to consider (and I don't understand the CRS well...).</strike>\n\n**Update:**\n\nSorry, I was wrong... `nc`'s CRS is EPSG 4267 and OpenStreetMap tiles use EPSG 4326. Thanks Edzer for [pointing this out](https://twitter.com/edzerpebesma/status/1005494350585978893)!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsf::st_crs(nc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoordinate Reference System:\n  User input: NAD27 \n  wkt:\nGEOGCRS[\"NAD27\",\n    DATUM[\"North American Datum 1927\",\n        ELLIPSOID[\"Clarke 1866\",6378206.4,294.978698213898,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4267]]\n```\n:::\n:::\n\n\nSo, I should have converted `nc` to the CRS first.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnc_4326 <- sf::st_transform(nc, 4326)\n```\n:::\n\n\nFortunately, the difference between EPSG 4267 and EPSG 4326 is rather negligible for this scale, so the result map should look almost same if I used `nc_4326` instead of `nc`. Here's the difference (can you see there's a little red colors?):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnc_4326_not_transformed <- sf::`st_crs<-`(nc, 4326)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n```\n:::\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = nc_4326_not_transformed, fill = \"transparent\", colour = \"red\") +\n  geom_sf(data = nc_4326, fill = \"transparent\", colour = \"blue\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/difference-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}